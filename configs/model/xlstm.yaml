pad_token_id: 1
vocab_size: 20_000
context_length: 256
num_blocks: 8
embedding_dim: 384

mlstm_block:
  mlstm:
    conv1d_kernel_size: 4
    qkv_proj_blocksize: 32
    num_heads: 4

slstm_block:
  slstm:
    backend: "vanilla"
    num_heads: 4
    conv1d_kernel_size: 4
    bias_init: "powerlaw_blockdependent"
  feedforward:
    proj_factor: 1.7
    act_fn: "swish"
